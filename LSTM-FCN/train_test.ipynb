{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate LSTM-FCN\n",
    "- Code source : https://github.com/metra4ok/MLSTM-FCN-Pytorch\n",
    "- Modified some sturcture and parameters w.r.t. our IOT hackathon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (dataset.py, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3398\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [53]\u001b[0;36m in \u001b[0;35m<cell line: 2>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from src.dataset import load_datasets\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Desktop/Github/IOT_hackathon/LSTM-FCN/src/dataset.py:3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from torch\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from src.model import SELayer, MLSTMfcn\n",
    "from src.dataset import load_datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Seed and Device setting\n",
    "\n",
    "def def_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def_seed(seed=123)\n",
    "\n",
    "if torch.has_cuda:\n",
    "    device = torch.device('cuda') \n",
    "elif torch.has_mps:\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device) # Print Using Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Structure\n",
    "- shape : [NUM_DATA, MAX_LENGTH, NUM_FEATURE]\n",
    "> 각 데이터별로(grid) time step에서의 state(value of each feature)을 1차원 텐서로, 모든 time step\n",
    "> 핵심 : time step의 최대길이는 맞춤(존재하지 않는다면, 0으로 값을 주어 길이를 동일하게)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validation(model, testloader, criterion, device=device):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for inputs, labels, seq_lens in testloader:\n",
    "        inputs = inputs.float()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        output = model.forward(inputs, seq_lens)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, validloader, criterion, optimizer, \n",
    "          epochs=10, print_every=10, device=device, run_name='model_mlstm_fcn'):\n",
    "    print(\"Training started on device: {}\".format(device))\n",
    "\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    steps = 0\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels, seq_lens in trainloader:\n",
    "            steps += 1\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(inputs, seq_lens)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    valid_loss, accuracy = validation(model, validloader, criterion, device)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.6f}.. \".format(train_loss/print_every),\n",
    "                      \"Val Loss: {:.6f}.. \".format(valid_loss/len(validloader)),\n",
    "                      \"Val Accuracy: {:.2f}%\".format(accuracy/len(validloader)*100))\n",
    "                \n",
    "                # save model if validation loss has decreased\n",
    "                if valid_loss <= valid_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                    valid_loss_min,\n",
    "                    valid_loss))\n",
    "                    torch.save(model.state_dict(), 'weights/'+run_name+'.pt')\n",
    "                    valid_loss_min = valid_loss\n",
    "\n",
    "                train_loss = 0\n",
    "\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "# variable\n",
    "NUM_CLASSES = 2\n",
    "MAX_SEQ_LEN = 8640 # 24*365\n",
    "NUM_FEATURES = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2819cb95bedbdbf0235ea4f18636776a6258e25e4398420083407874651edca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
